\documentclass[a4paper]{IEEEtran}

\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx} 
\usepackage{multirow, pgfplotstable,booktabs,colortbl,lmodern}

\newcommand\TODO[1]{\textcolor{red}{TODO:#1}}
\newcommand\todo[1]{\TODO{#1}}
\newcommand\cn{\textcolor{red}{[citation needed]}}

\title{A Comparison of Delta Correlation Prefetchers}

\author{
    Sigve Sebastian Farstad,
    Rune Holmgren,
    Torbjørn Langland,
    Per Thomas Lundal
}

\begin{document}

\maketitle

\begin{abstract}
    Le abstract.\cn
\end{abstract}

\section{Introduction}

\todo{ Write briefly about the project, the course it belongs to and the goal}
This is the introduction section.
Here we write something appealing for you to continue on.
If you finish this, you will be baked a cake.

As part of the course TDT4260 Computer Architecture, students in groups of 3 or 4 were to implement and test a prefetcher.
This report describes the implementation with test results done by group 11.
The report will describe the framework for the project, different prefetchers that have been implemented, how they work and the test results.

\section{Related Work}

\todo{ Not sure, mention related work?}
Here we mention related work. Do you want cake for your relatives?

\subsection{Delta Correlation Prefetching}

Stride Prefetching is based on identifying repeating memory address deltas.
The most recent delta along with some information describing its stability is stored and used to prefetch more cache lines.
The stability describes how many times the delta has repeated, and is used to determine how many cache lines to prefetch.
Programs such as those that use large arrays benefit greatly from Stride Prefetching, as they usually access memory in constant reapeating intervalls.

Delta Correlation Prefetching is a more advanced version of Stride Prefetching.
By storing a history of deltas instead of only the most recent, it is able to capture much more complex patterns than pure strides.
Figure \ref{fig:delta_stream} shows a repeating pattern that can be captured by Delta Correlation but not with Stride Prefetching.

\begin{figure}[!ht]
  \centering
      \includegraphics[width=0.5\textwidth]{Figures/DCExample}
  \caption{Example Delta Stream (Reprinted from \protect{\cite{dcpt}})}
  \label{fig:delta_stream}
\end{figure}

\subsection{Global History Buffer}

History based prefetchers need to store access patterns efficient data structure that enables quick access.
One such data structure is the Global History Buffer (GHB) \cite{ghb}.
GHB is an $n$-entry First-In, First-Out (FIFO) queue implemented as a circular buffer.
It stores the $n$ most recent L1 cache misses in entries that contain the miss address and a link pointer.
The link pointer is used to chain entries together into time-ordered linked lists that holds the significant access patterns.
An Index Table (IT) is used to keep track of these lists.
It maps some key to the most recent element of a linked list.
The IT is based on a FIFO queue like GHB, but significantly smaller as each entry has to be evaluated for each cache miss to look up a matching key.
The key can be based on any cache miss information, and depending on it a wide variety of history based prefetch methods can be implemented.
In a comparison of different prefetch mechanisms by Péres et al.\cite{microlib}, one using GHB gave the best performance.
\todo{figure}
\todo{less chance for data going stale}

\section{Prefetcher Description}

A total of 5 different prefetchers have been implemented and tested: CZone Delta Correlation, Adaptive CZone Delta Correlation, Program Counter Delta Correlation, Adaptive Program Counter Correlation, and Delta Correlation Prediction Table. 
What they have in common is that they all implement Delta Correlation, and four use Global History Buffer (GHB). 
The following subsections will describe the differences between these:

\subsection{CZone Delta Correlation}

\begin{figure}[h!]
  \centering
      \includegraphics[width=0.5\textwidth]{Figures/CDC}
  \caption{CZone Delta Correlation (Reprinted from \protect\cite{acdc}})
  \label{fig:CDC}
\end{figure}

Figure \ref{fig:CDC} shows how CZone Delta Correlation works. 
The memory is divided into different concentration zones (CZones). 
The reason behind this is that memory load patterns from different areas of the memory may be different from each other, and the idea is to calculate correct prefetch based on the CZones of the load addresses.
The contents of the index table are based on the different CZones, and the pointer belonging to a CZone points to the latest address from that CZone that is stored in the GHB.
Figure \ref{fig:CDC} shows an example of a CZone Delta Correlation Prefetcher that implements GHB and Delta Correlation. 
Tag C from the index table points to address C09 from CZone C is the head, and is linked to C08,  which again is linked to C06, etc. 
The first two address deltas (1 and 2) from the linked list is added to the Correlation Key Register (2 and 1 in the example). 
The list is traversed, and the Correlation Comparison Register is continiously uptdated with the two latest deltas. 
When the correlation of the deltas of addresses C2-C4-C5 and C6-C8-C9  occurs, a delta buffer is filled with the deltas from the traversed list so far, and a prefetch based on the latest addresses and the deltas is issued.
Addresses C11, C12, C13, C15 and C16 will be calculated and prefetched.
 
\todo{ Write about head pointer?} \break

\subsection{Adaptive CZone Delta Correlation}
This is a more advanced version of the CZone Delta Correlation Prefetcher.
While the non-adaptive version prefetches a static number of data blocks, this one dynamically calculates how many data blocks to prefetch.
The prefetcher increases or decreases the number of blocks to be prefetched by 1, after evaluating the hit rate.
The hit rate is compared with the hit rate of the previous setting, and the prefetcher increases or decreases the number of blocks based on increased or decreased performance. 

\subsection{Program Counter Delta Corelation}
\todo{write something}
A load instruction in the PC may be used several times to load data from different addresses on the memory.
Addresses of a load instruction that misses is read from the PC and placed in the Index table, and it points to the latest missed data address connected to that specific instruction address. 

\subsection{Adaptive Program Counter Delta Corelation}
\todo{write something}
This is a more advanced version of the Program Counter Delta Prefetcher, that calculates how many blocks to load by comparing hit rate performance on the current load number with the previous load number.

\subsection{Delta Correlation Prediction Tables}

\todo{Describe how the final prefetcher works. I suggest adding a figure. Maybe briefly mention other attempts while if we have space?}


As can be seen, the a row in the table contains fields for the PC, last address, last prefetch, deltas 1 to n, and delta pointer.
PC stores the address to the load instruction, and works as index in the table.
The Last Address stores the missed address when there is a miss in the cache.
The delta fields stores the address difference, or the deltas, for each time this instruction is called.
Last prefetch contains the address of the last issued prefetch.
The Delta Pointer points to the head (first Delta field) in the row, since the delta fields are used as circular buffer.

\begin{figure}[h!]
  \centering
      \includegraphics[width=0.5\textwidth]{Figures/DCTable}
  \caption{Delta Correlation Prediction Table}
  \label{fig:DCTable}
\end{figure}

\section{Methodology}

\todo{Mention the framework. Explain PFJudge. Maybe or maybe not mention C++?}


\subsection{Simulation Framework}

A modified version of M5, the open-source TCP/IP network simulator\cite{M5paper}, has been used to simulate a hierarchical memory environment for evaulation of the different prefetcher implementations.
The modified M5 simulator is supplied as course material.

The memory model simulated by the framework is based on the Alpha 21264 microprocessor, which is a superscalar processor capable of out-of-order execution through speculative execution and instruction reordering.

The modified M5 user guide documents the exact architecture details:

\begin{quote}
The L1 prefetcher is split in a 32kB instruction cache, and a 64kB data cache.
Each cache block is 64B.
The L2 cache size is 1MB, also with a cache block size of 64B.
The L2 prefetcher is notified on every access to the L2 cache, both hits and misses.
There is no prefetching for the L1 cache.

The memory bus runs at 400MHz, is 64 bits wide, and has a latency of 30ns.~\cite{m5userguide}
\end{quote}

To simulate a prefetcher with the modified M5 framework, the bahavior must be implemented as an M5 prefetcher module in C++ and plugged into the system.

\subsection{SPEC CPU2000}

To measure the performances of the different prefetchers, the prefetchers are simulated and observed during runs against a subset of the SPEC CPU2000 benchmark suite.~\cite{http://dl.acm.org/citation.cfm?id=621510}

\subsection{PFJudge}

PFJudge is a prefetcher judge system available through an online web interface.
It is used in this project to run the M5-based simulations.

\section{Results}

\todo{ Describe results from both local and PFJudge.}

\input{graphs.tex}

EXPLOSION!

\section{Discussion}

\todo{ Not exactly sure, just say it works better? Compare with other prefetcher IF we chose to describe them. }

You killed GLaDOS.
You monster.

\section{Conclusion}

\todo{ Mention what could have been done better or different? Future ideas? }

The cake is a lie!

\section{Acknowledgements (optional)}

GLaDOS

yoyo \cite{assignment-text}

\bibliography{bibliography}
\bibliographystyle{plain}
\nocite{*}

\end{document}
