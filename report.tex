\documentclass[a4paper]{IEEEtran}

\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx} 
\usepackage{multirow, pgfplotstable,booktabs,colortbl,lmodern}

\newcommand\TODO[1]{\textcolor{red}{TODO:#1}}
\newcommand\todo[1]{\TODO{#1}}
\newcommand\cn{\textcolor{red}{[citation needed]}}

\title{A Comparison of Delta Correlation Prefetchers}

\author{
    Sigve Sebastian Farstad,
    Rune Holmgren,
    Torbjørn Langland,
    Per Thomas Lundal
}

\begin{document}

\maketitle

\begin{abstract}
    This report examines the relative performances of different Delta Correlation prefetching schemes.
    Of the prefetchers tested, DCPT is shown experimentally to be the overall most performant prefetching scheme, but not by a land slide.

\end{abstract}

\section{Introduction}

This report is a solution to the mini-project for the course TDT4260 Computer Architecture at the Norwegian University of Science and Technology, spring 2014.
The assignment is to implement and evaluate the performance of one or more prefetchers. This report describes the implementation and test results done by group 11.

In this report, the relative performances of different Delta Correlation prefetchers is examined and discussed.

\section{Related Work}

\subsection{Delta Correlation Prefetching}

Delta Correlation Prefetching is a more advanced version of Stride Prefetching.
Stride Prefetching is based on identifying repeating memory address deltas.
The most recent delta along with some information describing its stability is stored and used to prefetch more cache lines.
The stability describes how many times the delta has repeated, and is used to determine how many cache lines to prefetch.
Programs such as those that use large arrays benefit greatly from Stride Prefetching, as they usually access memory in constant repeating intervals.

By storing a history of deltas instead of only the most recent, Data Correlation Prefetching is able to capture much more complex patterns than pure strides.
The history can then be searched for matches to the most recent deltas.
Each stored delta following the match would then be applied to the last address and prefethed.
It does however demand more storage space, which is proportional to the number of deltas.
Fig.~\ref{fig:delta_stream} shows a repeating pattern that can be captured by Delta Correlation but not with Stride Prefetching.
In the example, the two most recent deltas matches the first two, enabling a prefetch for address 31 and 40 to be issued.

\begin{figure}[!ht]
  \centering
      \includegraphics[width=0.35\textwidth]{Figures/DCExample}
  \caption{Example Delta Stream (Reprinted from \protect\cite{dcpt})}
  \label{fig:delta_stream}
\end{figure}

\subsection{Global History Buffer}

History based prefetchers need to store access patterns in efficient data structures that enable quick access.
One such data structure is the Global History Buffer (GHB) \cite{ghb} which is shown in Fig.~\ref{fig:ghb}.
GHB is an $n$-entry First-In, First-Out (FIFO) queue implemented as a circular buffer.
It stores the $n$ most recent L1 cache misses in entries that contain the miss address and a link pointer.
The link pointer is used to chain entries together into time-ordered linked lists that hold the significant access patterns.
An Index Table (IT) is used to keep track of these lists.
It maps some key to the most recent element of a linked list.
The IT is based on a FIFO queue like GHB, but significantly smaller as each entry has to be evaluated for each cache miss to look up a matching key.
The key can be based on any cache miss information, and depending on it a wide variety of history based prefetch methods can be implemented.

\begin{figure}[!ht]
  \centering
      \includegraphics[width=0.3\textwidth]{Figures/ghb}
  \caption{Global History Buffer Structure (Reprinted from \protect{\cite{ghb}})}
  \label{fig:ghb}
\end{figure}

By keeping only recent data, it is not subject to any significant amount of stale data, and is better able to capture current access patterns.
Programs changing between several regular patterns may however not benefit from this, as one pattern might fill the whole buffer, causing information of the other to be lost.
In a comparison of different prefetch mechanisms by Péres et al.\cite{microlib}, one using GHB gave the best performance.

\section{Prefetcher Description}

A total of 5 different prefetchers have been implemented and tested: CZone Delta Correlation, Adaptive CZone Delta Correlation, Program Counter Delta Correlation, Adaptive Program Counter Correlation, and Delta Correlation Prediction Table. 
What they have in common is that they all implement Delta Correlation, and four use Global History Buffer (GHB). 
The following subsections will describe the differences between these:

\subsection{CZone Delta Correlation}

\begin{figure}[!ht]
  \centering
      \includegraphics[width=0.5\textwidth]{Figures/CDC}
  \caption{CZone Delta Correlation (Reprinted from \protect\cite{acdc})}
  \label{fig:CDC}
\end{figure}

The concept of concentration zones (CZones) is based on the assumption that access within a data structure is fairly regular and that similar data structures lie within close proximity of each other in memory.
It works by dividing the memory into different regions, each assigned its own tag (most significant bits of the memory address).
Memory access patterns are then traced within these regions using Delta Correlation to determine prefetch candidates.

Fig.~\ref{fig:CDC} shows an example of a CZone Delta Correlation Prefetcher that is implemented using GHB. 
Tag C from the index table points to address C09 from CZone C is the head, and is linked to C08,  which again is linked to C06, etc. 
The first two address deltas (1 and 2) from the linked list is added to the Correlation Key Register (2 and 1 in the example). 
The list is traversed, and the Correlation Comparison Register is continuously updated with the two latest deltas. 
When the correlation of the deltas of addresses C2-C4-C5 and C6-C8-C9  occurs, a delta buffer is filled with the deltas from the traversed list so far, and a prefetch based on the latest addresses and the deltas is issued.
Addresses C11, C12, C13, C15 and C16 will be calculated and prefetched.
 
\todo{ Write about head pointer?} \break

\subsection{Adaptive CZone Delta Correlation}
This is a more advanced version of the CZone Delta Correlation Prefetcher.
While the non-adaptive version prefetches a static number of data blocks, this one dynamically calculates how many data blocks to prefetch.
The prefetcher increases or decreases the number of blocks to be prefetched by 1, after evaluating the hit rate.
The hit rate is compared with the hit rate of the previous setting, and the prefetcher increases or decreases the number of blocks based on increased or decreased performance. 

\subsection{Program Counter Delta Correlation}
\todo{write something}
A load instruction in the PC may be used several times to load data from different addresses on the memory.
Addresses of a load instruction that misses is read from the PC and placed in the Index table, and it points to the latest missed data address connected to that specific instruction address. 

\subsection{Adaptive Program Counter Delta Correlation}
\todo{write something}
This is a more advanced version of the Program Counter Delta Prefetcher, that calculates how many blocks to load by comparing hit rate performance on the current load number with the previous load number.

\subsection{Delta Correlation Prediction Tables}

\todo{Describe how the final prefetcher works. I suggest adding a figure. Maybe briefly mention other attempts while if we have space?}


As can be seen, a row in the table contains fields for the PC, last address, last prefetch, deltas 1 to $ n $, and delta pointer.
PC stores the address to the load instruction, and works as index in the table.
The Last Address stores the missed address when there is a miss in the cache.
The delta fields stores the address difference, or the deltas, for each time this instruction is called.
Last prefetch contains the address of the last issued prefetch.
The Delta Pointer points to the head (first Delta field) in the row, since the delta fields are used as circular buffer.

\begin{figure}[h!]
  \centering
      \includegraphics[width=0.5\textwidth]{Figures/DCTable}
  \caption{Delta Correlation Prediction Table}
  \label{fig:DCTable}
\end{figure}

\section{Methodology}

In order to measure prefetcher performance, a test bench had to be made.
Software implementations of the different prefetcher behaviors were implemented nd simulated in a simulation framework.

\subsection{Simulation Framework}

A modified version of M5, the open-source TCP/IP network simulator\cite{M5paper}, has been used to simulate a hierarchical memory environment for evaluation of the different prefetcher implementations.
The modified M5 simulator is supplied as course material.

The memory model simulated by the framework is based on the Alpha 21264 microprocessor, which is a superscalar processor capable of out-of-order execution through speculative execution and instruction reordering.

The modified M5 user guide documents the exact architecture details:

\begin{quote}
The L1 prefetcher is split in a 32kB instruction cache, and a 64kB data cache.
Each cache block is 64B.
The L2 cache size is 1MB, also with a cache block size of 64B.
The L2 prefetcher is notified on every access to the L2 cache, both hits and misses.
There is no prefetching for the L1 cache.

The memory bus runs at 400MHz, is 64 bits wide, and has a latency of 30ns.~\cite{m5userguide}
\end{quote}

To simulate a prefetcher with the modified M5 framework, the behavior must be implemented as an M5 prefetcher module in C++ and plugged into the system.
To emulate realistic conditions for a hardware prefetcher implementation, a hard memory usage limit of 8KB was imposed on the software prefetchers.
That means that a prefetcher may only allocate up to 8KB of memory to hold any eventual data structures.
No further restrictions were imposed.

\subsection{SPEC CPU2000}

To measure the performances of the different prefetchers, the prefetchers were simulated and observed during runs against a subset of the SPEC CPU2000 benchmark suite.~\cite{http://dl.acm.org/citation.cfm?id=621510}

The benchmarks measure several key performance indicators:

\subsubsection{Speedup}
Speedup is the total execution speedup gained by using a given prefetcher compared to having no prefetcher at all.

\subsubsection{IPC}
IPC, or Instructions Per Cycle, measures how many instructions are executed per clock cycle of the processor.
Since the simulated M5 architecture is superscalar, this number can be greater than 1.

\subsubsection{Accuracy}
Accuracy is a measure that shows how many prefetches were useful.

\subsubsection{Coverage}
Coverage is a measurement that answers the question of how many potential prefetch candidates were identified by the prefetcher.

\subsubsection{Identified}
Identified is a measure that shows how many prefetches have been issued to the cache controller by the prefetcher.

\subsubsection{Issued}
Issued is a measure that shows how many prefetches have been issued to the next memory hierarchy level by the cache controller.

\subsection{PFJudge}

PFJudge is a prefetcher judge system available through an online web interface.
It is used in this project to run the M5-based simulations.

\subsection{Development}

\todo{explain how the prefetchers were developed.}

\section{Results}

The results from the benchmark runs are shown in Fig. \ref{fig:results}.

\input{graphs.tex}

\section{Discussion}

The first observation that can be made is that Delta Correlation prefetchers are generally more performant than simply using no prefetcher at all.
The exception to this is the CPC prefetcher, which is twice as slow as the other Delta Correlation prefetchers tested in the \texttt{ammp} test.
Indeed, it is even considerably worse than using no prefetcher at all.
The reason for this abysmal behavior can be seen in the accuracy statistics for the same test.
Where the other prefetchers have scored around 0.8 accuracy, which is quite good, CPC has scored less than one hundredth of that.
To have a prefetcher which is vulnerable to extremely poor performance in some secenarios is a bad idea, as it is at best inefficient, and at worst downright dangerous.
CPC is the only one of the tested prefetchers that have exhibited this kind of behavior.

Other than the extreme discrepancy in the CPC \texttt{amms} test, there are not a lot of big differences.
Some tests favor one pretching scheme, while other tests favor another.
Overall, DCPT scores best on average with APCDC a close second.
Which one should be chosen over the other for use in a given real life application, however, largely depends on the characteristics of the application.

\input{discussion_graph.tex}

\section{Conclusion}

\todo{ Mention what could have been done better or different? Future ideas? }

In conclusion, while Delta Correlation based prefetching approaches are promising in general, there are some significant differences between the prefetching schemes tested.
The differences, however, are not uniformly in favor of a single prefetching scheme.
The benchmarks rather favor different schemes for different tests.

Looking at the average speedup, though, DCPT emerges as the most performant scheme, while CPC is the least performant scheme.



\bibliography{bibliography}
\bibliographystyle{plain}
\nocite{*}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/farstad.jpg}}]{Sigve Sebastian Farstad}
    was born in Trondheim, Norway, in 1990.
    He is currently working towards an M.S. degree in computer science from the Norwegian University of Science and Technology, Trondheim, expecting to graduate in 2015.

    In 2009 he served as a civilian guardian of the Norwegian People, and he has since then worked as, amongst other things, a Software Consultant, a Technical Innovator in the mobile banking sector, a Professional Translator, and is currently working as one of the technical Co-Founders of feat.fm.

    Mr. Farstad was, together with other team members of the demo crew Ninjadev, the winner of the Web Demo Compo at Solskogen 2012.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/holmgren.jpg}}]{Rune Holmgren}
    was born in Harstad, Norway, in 1991.
    He is currently working towards an M.S. degree in computer science from the Norwegian University of Science and Technology, Trondheim, expecting to graduate in 2015.

    He has worked as a Dairy Product Quality Assurance Intern, a Teaching Assistant for and most recently held the position of Summer Intern at Connome.

    Mr. Holmgren was recipient of the award Friidrettens Venners Kretspris in 2010.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/langland.jpg}}]{Torbjørn Langland}
    was born in Trondheim, Norway, in 1987.
    He is currently working towards an M.S. degree in computer science from the Norwegian University of Science and Technology, Trondheim, expecting to graduate in 2015.

    He was worked as a Temporary Store Clerk and until recently held the title of Software Engineer at Comsol.

    Mr Langland is exceptionally good at playing Mario Kart 64.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/lundal.jpg}}]{Per Thomas Lundal}
    was born in Trondheim, Norway, in 1991.
    He is currently working towards an M.S. degree in computer science from the Norwegian University of Science and Technology, Trondheim, expecting to graduate in 2015.

    He has since 2006 worked as a Sales Representative at Biltema.
    He has also worked as a Teaching Assistant for the course Programming Languages at NTNU.

    Mr. Lundal was the recipient of the Champions' Award and the Programming Award at the First Lego League, Trondheim.
\end{IEEEbiography}

\end{document}
